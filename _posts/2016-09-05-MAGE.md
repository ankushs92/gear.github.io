---
layout: post
type: project
title: Motif-Aware Graph Embedding
subtitle: The benefit of guilding random walks by motifs
---

Recently, the field of graph embedding takes off by the adaptation of [Skipgram](https://)
model on graphs. The pioneer paper "[Deepwalk: bla bla](https://)" on this topic was
published in KDD'14 by Peperozi et al. I [presented](https://) this paper at a meet up at 
University of Tokyo on graph embedding in early 2016. In a nutshell, graph embedding _is_
word embedding. If we think of word and vertex as a same entity, the 
algorithm to learn a projection of a word token to some d-dimension real vector space can
be applied to a vertex in a graph to do the similar embedding. Thanks to some similarity 
between the frequency of verticies in random walks and words count in text, the authors 
of _Deepwalk_ has proposed to use random walks on a graph as a tool to generate the 
_graph context_. For me, I view such scheme as a duality. (I **love** duality)

| | Text | Graph |
| :--- | :--- | :--- |
| Token | Word | Vertex |
| Structure | Sentences | Connections |
| Distribution | Power law (frequency) | Power law (social networks) |
