---
layout: post
type: math
title: Empirical Rish Minimization
subtitle: A gentle approach to theoretical machine learning
---

I remember the confusion I had when professor [Osamu Watanabe](http://www.is.titech.ac.jp/~watanabe/)
first gave me the Occam's razor problem. With that confusion, I start to love the
exciting world of theoretical machine learning. In this post, I will explain the basic
of theoretical machine learning starting with ERM. 

Empirical Rish Minimization (ERM) is a class of algorithm that returns the hypothesis $$h$$
that minimizes $$L_S(h)$$ given a set of training samples $$S$$. The empirical risk is 
defined as:

$$ L_S(h) = \frac{|\{i \in [m]: h(x_i) \neg f(x_i)\}|}{m} $$

This formula can be read as: The _empirical risk_ (subscript S denotes the risk is based
on the training set $$S$$ of size $$m$$ only) is the number of samples ($$x_i$$) that our 
predictor $$h$$ doesn't match with the true labeling function $$f$$.

You can write regular [markdown](http://markdowntutorial.com/) here and Jekyll will automatically convert it to a nice webpage.  I strongly encourage you to [take 5 minutes to learn how to write in markdown](http://markdowntutorial.com/) - it'll teach you how to transform regular text into bold/italics/headings/tables/etc.

**Here is some bold text**

## Here is a secondary heading

Here's a useless table:
 
| Number | Next number | Previous number |
| :------ |:--- | :--- |
| Five | Six | Four |
| Ten | Eleven | Nine |
| Seven | Eight | Six |
| Two | Three | One |
 

How about a yummy crepe?

![Crepe](http://s3-media3.fl.yelpcdn.com/bphoto/cQ1Yoa75m2yUFFbY2xwuqw/348s.jpg)

Here's a code chunk:

~~~
var foo = function(x) {
  return(x + 5);
}
foo(3)
~~~

And here is the same code with syntax highlighting:

```javascript
var foo = function(x) {
  return(x + 5);
}
foo(3)
```

And here is the same code yet again but with line numbers:

{% highlight javascript linenos %}
var foo = function(x) {
  return(x + 5);
}
foo(3)
{% endhighlight %}
