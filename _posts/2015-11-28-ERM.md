---
layout: post
type: math
title: Empirical Rish Minimization
subtitle: Some intuitions and problems
---

I remember the confusion I had when professor [Osamu Watanabe](http://www.is.titech.ac.jp/~watanabe/)
first gave me the Occam's razor problem. With that confusion, I start to love the
exciting world of theoretical machine learning. This post is about ERM scheme and 
some proofs around it.

## Playground

Here are some notations and scheme for our playground:

- Data space: $$\mathcal{X}$$ - Where we "draw" data samples.
- Data distribution: $$\mathcal{D}$$ - How the data in $$\mathcal{X}$$ is distributed.
- Label space: $$\mathcal{Y}$$ - Where we have the labels for our samples.
- Labeling function: $$f: \mathcal{X} \mapsto \mathcal{Y}$$ - Given a data sample, return its true label.
- Training set: $$S$$ of size $$\|S\| = m$$ - The set of training samples and its training labels.
- Hypotheses class: $$\mathcal{H}$$ - A finite set of hypotheses $$h$$. 
- Hypothesis: $$h$$ - An estimation of $$f$$, $$h$$ is the result of some learning algorithm and $$S$$.
- **Our task**: Given a training set $$S$$, we do not know $$D$$ or $$f$$ for all data points, how do
we argue about the _quality_ of the learned hypothesis $$h$$ compared to $$f$$?

## Measuring risk on training dataset

Empirical Rish Minimization (ERM) is a class of algorithm that returns the hypothesis $$h$$
that minimizes $$L_S(h)$$ given a set of training samples $$S$$. The empirical risk is 
defined as:

$$ L_S(h) = \frac{|\{i \in [m]: h(x_i) \neq f(x_i)\}|}{m} $$

This formula can be read as: The _empirical risk_ is the number of samples ($$x_i$$) at which our 
predictor $$h$$ doesn't match with the true labeling function $$f$$ (subscript S denotes the risk is based
on the training set $$S$$ of size $$m$$ only). In this scheme, we are given a set of hypotheses
$$\mathcal{H}$$, a data space $$\mathcal{X}$$, a distribution $$\mathcal{D}$$ over the data space
$$\mathcal{X}$$, and a labeling function $$f: \mathcal{X} \mapsto \mathcal{Y}$$ that labels a
data samples to its "true" label. **An algorithm is called ERM when it returns the hypothesis
that minimizes the empirical risk**. In another word, empirical risk can be viewed as the loss
over the training data $$S$$. The weakness of _empirical risk_ (or empirical loss) is when the
training samples set $$S$$ contains only _misleading samples_. 

Idealistically, we want to know the **error of a prediction rule** $$L_{D,f}(h)$$. This term
can be interpreted as the error of predictor $$h$$ over (evaluated on) the data distribution $$D$$ 
and the labeling function $$f$$. The true loss! However, the data distribution $$D$$ and the true 
labeling function $$f$$ typically are not available in practice. Therefore, we have to rely on the 
empirical risk, which is evaluated on the training data $$S$$. By definition, the (true) **error
of a prediction rule** is:

$$ L_{D,f}(h) = \underset{x \sim \mathcal{D}} P [h(x) \neq f(x)] = \mathcal{D}(\{x : h(x) \neq f(x)\}) $$

The error of a prediction rule is the probability that it returns a wrong label, given a 
data sample $$x_i$$ from $$\mathcal{D}$$.

## Overfitting

Since the risk (loss) is measured on the training data $$S$$, ERM is prone to over
fitting. Simply speaking, the output hypothesis $$h$$ from ERM can just map training
samples to training labels. If such hypothesis is chosen, the risk $$L_S(h)$$ will 
be 0, but **we do not know if we have a good hypothesis or not**. Let's call the
minimum acceptable _true_ risk $$L_{D,f}(h)$$ epsilon ($$\epsilon$$), and have two 
assumption:

- Each data sample in $$S$$ is distributed independently and identically (i.i.d.).
- There exists $$h^* \in \mathcal{H}$$ s.t. $$L_{D,f}(h^*) = 0$$ (Realizability Assumption).

## Here is a secondary heading

Here's a useless table:
 
| Number | Next number | Previous number |
| :------ |:--- | :--- |
| Five | Six | Four |
| Ten | Eleven | Nine |
| Seven | Eight | Six |
| Two | Three | One |
 

How about a yummy crepe?

![Crepe](http://s3-media3.fl.yelpcdn.com/bphoto/cQ1Yoa75m2yUFFbY2xwuqw/348s.jpg)

Here's a code chunk:

~~~
var foo = function(x) {
  return(x + 5);
}
foo(3)
~~~

And here is the same code with syntax highlighting:

```javascript
var foo = function(x) {
  return(x + 5);
}
foo(3)
```

And here is the same code yet again but with line numbers:

{% highlight javascript linenos %}
var foo = function(x) {
  return(x + 5);
}
foo(3)
{% endhighlight %}
